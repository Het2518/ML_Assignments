{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11539557",
   "metadata": {},
   "source": [
    "# Assignment 4 ‚Äî Logistic Regression (Beginner-friendly, step-by-step)\n",
    "\n",
    "**What this notebook contains (simple language):**\n",
    "- Load two provided datasets: `ex2data1` and `ex2data2`.\n",
    "- Show the data (first rows) and visualize features `x1` vs `x2` with points colored by label (0 or 1).\n",
    "- Implement **logistic regression from scratch** (we write `sigmoid`, `cost`, `gradient`, `gradient_descent`, `predict` by hand ‚Äî no sklearn or optimizer functions).\n",
    "- Use **70%** of data for training and **30%** for testing (manually split using numpy permutation).\n",
    "- For the second dataset (non-linear), map features into polynomial features and train **regularized** logistic regression.\n",
    "- Plot the decision boundary for both datasets (linear boundary for dataset 1; contour for dataset 2).\n",
    "\n",
    "> The code is written for *beginners*: lots of comments, small helper functions, and step-by-step calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c9fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready. Files expected at:\n",
      "ex2data1-logistic - ex2data1.csv\n",
      "ex2data2-logistic - ex2data2.csv\n"
     ]
    }
   ],
   "source": [
    "# Imports and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For interactive DataFrame preview within this environment (helps beginners)\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "except Exception:\n",
    "    display_dataframe_to_user = None\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# File paths (these files were uploaded into /mnt/data)\n",
    "file1 = 'ex2data1-logistic - ex2data1.csv'\n",
    "file2 = 'ex2data2-logistic - ex2data2.csv'\n",
    "\n",
    "print('Ready. Files expected at:')\n",
    "print(file1)\n",
    "print(file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe68998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex2data1 shape: (101, 3)\n",
      "ex2data2 shape: (119, 3)\n",
      "\n",
      "ex2data1 (first 5 rows):\n",
      "            x1           x2  y\n",
      "0           x1           x2  y\n",
      "1  34.62365962  78.02469282  0\n",
      "2  30.28671077  43.89499752  0\n",
      "3  35.84740877  72.90219803  0\n",
      "4  60.18259939   86.3085521  1\n",
      "\n",
      "ex2data2 (first 5 rows):\n",
      "          x1       x2  y\n",
      "0         x1       x2  y\n",
      "1   0.051267  0.69956  1\n",
      "2  -0.092742  0.68494  1\n",
      "3   -0.21371  0.69225  1\n",
      "4     -0.375  0.50219  1\n"
     ]
    }
   ],
   "source": [
    "# Load the CSVs into pandas DataFrames and show top rows\n",
    "df1 = pd.read_csv(file1, header=None, names=['x1','x2','y'])\n",
    "df2 = pd.read_csv(file2, header=None, names=['x1','x2','y'])\n",
    "\n",
    "print('ex2data1 shape:', df1.shape)\n",
    "print('ex2data2 shape:', df2.shape)\n",
    "\n",
    "# Display first 5 rows (using special display helper if available)\n",
    "if display_dataframe_to_user is not None:\n",
    "    display_dataframe_to_user('ex2data1 head', df1.head())\n",
    "    display_dataframe_to_user('ex2data2 head', df2.head())\n",
    "else:\n",
    "    print('\\nex2data1 (first 5 rows):')\n",
    "    print(df1.head())\n",
    "    print('\\nex2data2 (first 5 rows):')\n",
    "    print(df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd57ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper to plot x1 vs x2 with different markers for labels 0 and 1\n",
    "def plot_data(X, y, title='Data (x1 vs x2)'):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    mask0 = (y == 0)\n",
    "    mask1 = (y == 1)\n",
    "    # two scatter calls will use default matplotlib color cycle (no explicit colors set)\n",
    "    plt.scatter(X[mask0,0], X[mask0,1], marker='o', label='label 0')\n",
    "    plt.scatter(X[mask1,0], X[mask1,1], marker='x', label='label 1')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize dataset 1\n",
    "X1 = df1[['x1','x2']].values\n",
    "y1 = df1['y'].values\n",
    "plot_data(X1, y1, title='ex2data1: x1 vs x2 (labels 0 and 1)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b63b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core logistic regression functions (vectorized) ---\n",
    "\n",
    "def sigmoid(z):\n",
    "    # Numerically-stable sigmoid\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def compute_cost(theta, X, y, lambda_=0.0):\n",
    "    # X: (m, n), theta: (n,), y: (m,)\n",
    "    m = len(y)\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    eps = 1e-15\n",
    "    cost = - (1.0/m) * (np.dot(y, np.log(h + eps)) + np.dot((1-y), np.log(1-h + eps)))\n",
    "    # regularization (do not regularize theta[0])\n",
    "    reg = (lambda_ / (2*m)) * np.sum(theta[1:] ** 2)\n",
    "    return cost + reg\n",
    "\n",
    "def compute_gradient(theta, X, y, lambda_=0.0):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    grad = (1.0/m) * (X.T.dot(h - y))\n",
    "    # regularize gradient (except theta[0])\n",
    "    grad[1:] = grad[1:] + (lambda_ / m) * theta[1:]\n",
    "    return grad\n",
    "\n",
    "def gradient_descent(X, y, theta_init, alpha=0.01, num_iters=1000, lambda_=0.0, verbose=False):\n",
    "    theta = theta_init.copy()\n",
    "    J_history = []\n",
    "    for i in range(num_iters):\n",
    "        grad = compute_gradient(theta, X, y, lambda_)\n",
    "        theta = theta - alpha * grad\n",
    "        J = compute_cost(theta, X, y, lambda_)\n",
    "        J_history.append(J)\n",
    "        if verbose and (i % (num_iters//5 + 1) == 0):\n",
    "            print(f'Iter {i}/{num_iters}, cost = {J:.6f}')\n",
    "    return theta, np.array(J_history)\n",
    "\n",
    "def predict(theta, X):\n",
    "    probs = sigmoid(X.dot(theta))\n",
    "    return (probs >= 0.5).astype(int)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c59d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual train/test split (70% train, 30% test)\n",
    "def train_test_split_manual(X, y, test_size=0.3, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    m = len(y)\n",
    "    indices = np.random.permutation(m)\n",
    "    test_count = int(np.round(m * test_size))\n",
    "    test_idx = indices[:test_count]\n",
    "    train_idx = indices[test_count:]\n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c259a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (71, 3) Test shape: (30, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m alpha = \u001b[32m0.1\u001b[39m\n\u001b[32m     15\u001b[39m iters = \u001b[32m3000\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m theta_learned, J_hist = \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iters\u001b[49m\u001b[43m=\u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLearned theta for ex2data1:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(theta_learned)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mgradient_descent\u001b[39m\u001b[34m(X, y, theta_init, alpha, num_iters, lambda_, verbose)\u001b[39m\n\u001b[32m     27\u001b[39m J_history = []\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     grad = \u001b[43mcompute_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     theta = theta - alpha * grad\n\u001b[32m     31\u001b[39m     J = compute_cost(theta, X, y, lambda_)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mcompute_gradient\u001b[39m\u001b[34m(theta, X, y, lambda_)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_gradient\u001b[39m(theta, X, y, lambda_=\u001b[32m0.0\u001b[39m):\n\u001b[32m     18\u001b[39m     m = \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     h = sigmoid(\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     20\u001b[39m     grad = (\u001b[32m1.0\u001b[39m/m) * (X.T.dot(h - y))\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# regularize gradient (except theta[0])\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "# Prepare X with intercept for ex2data1\n",
    "X = X1.copy()\n",
    "m = X.shape[0]\n",
    "X_with_intercept = np.concatenate([np.ones((m,1)), X], axis=1)  # shape (m, 3)\n",
    "\n",
    "# Split 70/30 (seed for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split_manual(X_with_intercept, y1, test_size=0.3, seed=RANDOM_SEED)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "# Initialize theta\n",
    "initial_theta = np.zeros(X_train.shape[1])\n",
    "\n",
    "# Train using gradient descent\n",
    "alpha = 0.1\n",
    "iters = 3000\n",
    "theta_learned, J_hist = gradient_descent(X_train, y_train, initial_theta, alpha=alpha, num_iters=iters, lambda_=0.0, verbose=True)\n",
    "\n",
    "print('\\nLearned theta for ex2data1:')\n",
    "print(theta_learned)\n",
    "\n",
    "# Plot cost history\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(np.arange(len(J_hist)), J_hist)\n",
    "plt.title('Cost history (ex2data1)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on train and test\n",
    "y_train_pred = predict(theta_learned, X_train)\n",
    "y_test_pred = predict(theta_learned, X_test)\n",
    "print('Train accuracy (ex2data1):', accuracy_score(y_train, y_train_pred))\n",
    "print('Test  accuracy (ex2data1):', accuracy_score(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ee587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundary for ex2data1\n",
    "# Linear decision boundary: theta0 + theta1*x1 + theta2*x2 = 0 -> x2 = -(theta0 + theta1*x1)/theta2\n",
    "plt.figure(figsize=(6,5))\n",
    "# plot data points (without explicit colors)\n",
    "plot_data(X[:,1:], y1, title='ex2data1 with decision boundary (train+test)')\n",
    "\n",
    "# choose two x values for line\n",
    "x_vals = np.array([X[:,1].min() - 1, X[:,1].max() + 1])\n",
    "# compute corresponding y values for boundary line\n",
    "if abs(theta_learned[2]) > 1e-8:\n",
    "    y_vals = -(theta_learned[0] + theta_learned[1] * x_vals) / theta_learned[2]\n",
    "    plt.plot(x_vals, y_vals, label='Decision boundary')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('theta[2] is nearly zero, cannot plot linear boundary.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e54521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_feature(x1, x2, degree=6):\n",
    "    # x1 and x2 are 1D arrays of the same length\n",
    "    if x1.ndim > 1:\n",
    "        x1 = x1.ravel()\n",
    "    if x2.ndim > 1:\n",
    "        x2 = x2.ravel()\n",
    "    out = [np.ones(x1.shape[0])]\n",
    "    for i in range(1, degree+1):\n",
    "        for j in range(i+1):\n",
    "            term = (x1 ** (i-j)) * (x2 ** j)\n",
    "            out.append(term)\n",
    "    return np.stack(out, axis=1)  # shape (m, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset 2\n",
    "X2 = df2[['x1','x2']].values\n",
    "y2 = df2['y'].values\n",
    "\n",
    "# Map features to polynomial terms up to degree 6 (common choice for this exercise)\n",
    "X2_mapped = map_feature(X2[:,0], X2[:,1], degree=6)\n",
    "print('Mapped feature shape (ex2data2):', X2_mapped.shape)\n",
    "\n",
    "# Now do 70/30 split on the mapped features\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split_manual(X2_mapped, y2, test_size=0.3, seed=RANDOM_SEED)\n",
    "\n",
    "# Feature scaling (standardize) for mapped features EXCEPT the intercept column (first column is ones)\n",
    "def standardize_features(X_train, X_test):\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    # skip column 0\n",
    "    mu = np.mean(X_train[:,1:], axis=0)\n",
    "    sigma = np.std(X_train[:,1:], axis=0, ddof=0)\n",
    "    # avoid division by zero\n",
    "    sigma[sigma == 0] = 1.0\n",
    "    X_train_scaled[:,1:] = (X_train[:,1:] - mu) / sigma\n",
    "    X_test_scaled[:,1:] = (X_test[:,1:] - mu) / sigma\n",
    "    return X_train_scaled, X_test_scaled, mu, sigma\n",
    "\n",
    "X2_train_scaled, X2_test_scaled, mu_map, sigma_map = standardize_features(X2_train, X2_test)\n",
    "print('After scaling, sample feature mean (train, skip intercept):', np.mean(X2_train_scaled[:,1:], axis=0)[:5], '...')\n",
    "print('Train shape (mapped & scaled):', X2_train_scaled.shape)\n",
    "\n",
    "# Train regularized logistic regression on mapped features\n",
    "initial_theta2 = np.zeros(X2_train_scaled.shape[1])\n",
    "alpha2 = 1.0     # learning rate (we use a larger rate; watch cost to ensure it decreases)\n",
    "iters2 = 4000    # number of iterations\n",
    "lambda_reg = 1.0  # regularization strength\n",
    "\n",
    "theta2_learned, J_hist2 = gradient_descent(X2_train_scaled, y2_train, initial_theta2,\n",
    "                                          alpha=alpha2, num_iters=iters2, lambda_=lambda_reg, verbose=True)\n",
    "\n",
    "print('\\nLearned theta (first 10 values) for ex2data2:')\n",
    "print(theta2_learned[:10])\n",
    "\n",
    "# Plot cost history for ex2data2\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(np.arange(len(J_hist2)), J_hist2)\n",
    "plt.title('Cost history (ex2data2, regularized)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate\n",
    "y2_train_pred = predict(theta2_learned, X2_train_scaled)\n",
    "y2_test_pred = predict(theta2_learned, X2_test_scaled)\n",
    "print('Train accuracy (ex2data2):', accuracy_score(y2_train, y2_train_pred))\n",
    "print('Test  accuracy (ex2data2):', accuracy_score(y2_test, y2_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points and contour decision boundary for ex2data2\n",
    "plt.figure(figsize=(7,6))\n",
    "plot_data(X2, y2, title='ex2data2 with decision boundary (mapped features)')\n",
    "\n",
    "# Create a grid to evaluate model\n",
    "u_vals = np.linspace(X2[:,0].min() - 1, X2[:,0].max() + 1, 200)\n",
    "v_vals = np.linspace(X2[:,1].min() - 1, X2[:,1].max() + 1, 200)\n",
    "U, V = np.meshgrid(u_vals, v_vals)\n",
    "# Map grid to polynomial features the same way and scale using mu_map and sigma_map\n",
    "UV_mapped = map_feature(U.ravel(), V.ravel(), degree=6)\n",
    "# scale using mu_map and sigma_map (for columns 1:)\n",
    "UV_mapped[:,1:] = (UV_mapped[:,1:] - mu_map) / sigma_map\n",
    "\n",
    "# Compute z = X * theta\n",
    "Z = UV_mapped.dot(theta2_learned)\n",
    "Z = Z.reshape(U.shape)\n",
    "\n",
    "# contour where Z = 0 (decision boundary). This draws where model predicts probability 0.5\n",
    "plt.contour(U, V, Z, levels=[0], linewidths=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c0b0f",
   "metadata": {},
   "source": [
    "## Summary (what we did)\n",
    "- Visualized both datasets (`ex2data1`, `ex2data2`).\n",
    "- Implemented logistic regression **from scratch** with vectorized numpy operations (sigmoid, cost, gradient, gradient descent).\n",
    "- Used a manual 70/30 train/test split.\n",
    "- For `ex2data1` (linear separable-ish): trained a linear logistic model and plotted a straight-line decision boundary.\n",
    "- For `ex2data2` (non-linear): mapped features to polynomial features up to degree 6, applied regularization, trained via gradient descent, and plotted a contour decision boundary.\n",
    "\n",
    "**Files created:** `/mnt/data/assignment_logistic_regression.ipynb` ‚Äî you can download and open this in Jupyter Notebook or Google Colab to step through code cell-by-cell.\n",
    "\n",
    "If you'd like, I can now:\n",
    "- reduce comments to make the notebook shorter,\n",
    "- add more explanation cells (math derivations for logistic loss and gradient), or\n",
    "- convert this notebook to a downloadable PDF/HTML.\n",
    "\n",
    "Tell me which one you prefer next, or just download and run the notebook! üëç\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
